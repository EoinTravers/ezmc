{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sys import stdout\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload stuff\n",
    "from importlib import reload\n",
    "import ezmc\n",
    "reload(ezmc)\n",
    "reload(ezmc.base)\n",
    "reload(ezmc.metropolis)\n",
    "import ezmc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work through a more realistic example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from numba import jit\n",
    "\n",
    "'''Helper functions'''\n",
    "def invlogit(lo):\n",
    "    o = np.exp(lo)\n",
    "    return o / (1 + o)\n",
    "\n",
    "def logit(p):\n",
    "    o = p / (1 - p)\n",
    "    return np.log(o)\n",
    "\n",
    "def edge_correct(x, e):\n",
    "    x = np.where(x < 0, 0, x)\n",
    "    x = np.where(x >1,  1, x)\n",
    "    # assert(np.all(x >= -e) & np.all(x <= 1+e))\n",
    "    return x + e*(.5-x)\n",
    "\n",
    "def generate_outcomes(ntrials=200, probs=[.1, .9], min_len=10, max_len=20):\n",
    "    '''\n",
    "    Generates outcomes for a reversal learning paradigm,\n",
    "    where reward contingencies reverse every `min_len` to `max_len` trials.\n",
    "    Returns a list of 0s and 1s.\n",
    "    '''\n",
    "    block_lengths = np.random.choice(range(min_len, max_len), 50)\n",
    "    probs = itertools.cycle(probs)\n",
    "    probabilities = np.concatenate([np.repeat(p, n)\n",
    "                                    for p, n in zip(probs, block_lengths)])\n",
    "    probabilities = probabilities[:ntrials]\n",
    "    outcomes = np.random.binomial(1, probabilities)\n",
    "    return outcomes\n",
    "\n",
    "\n",
    "@jit() # Numba jit speeds this up considerably.\n",
    "def rw_update(outcomes, learning_rate, start=.5):\n",
    "    '''Rescorla-Wagner learning rule'''\n",
    "    p = start\n",
    "    predictions = np.zeros(len(outcomes))\n",
    "    for i, o in enumerate(outcomes):\n",
    "        predictions[i] = p\n",
    "        pe = o - p\n",
    "        p += pe * learning_rate\n",
    "    return predictions\n",
    "\n",
    "def get_agent_response_probs(outcomes, learning_rate, slope):\n",
    "    '''\n",
    "    Given a set of outcomes, a learning rate, and a decision slope (inverse temperature),\n",
    "    how likely is the agent to respond 0 or 1?\n",
    "    '''\n",
    "    n = len(outcomes)\n",
    "    beliefs = rw_update(outcomes, learning_rate)\n",
    "    beliefs = edge_correct(beliefs, .001)\n",
    "    action_probs = invlogit(logit(beliefs) * slope)\n",
    "    return action_probs\n",
    "\n",
    "def get_agent_responses(outcomes, learning_rate, slope):\n",
    "    '''\n",
    "    Simulates binary responses by a RL agent.\n",
    "    '''\n",
    "    action_probs = get_agent_response_probs(outcomes, learning_rate, slope)\n",
    "    responses = np.random.binomial(1, action_probs)\n",
    "    return responses, action_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_pars = [.5, 0.] # Learning rate, Slope\n",
    "# true_pars = [1, 1.] # Learning rate, Slope\n",
    "true_pars = [.2, 1.]\n",
    "\n",
    "outcomes = generate_outcomes(ntrials=1000, probs=[.2, .8], min_len=10, max_len=20)\n",
    "responses, action_probs = get_agent_responses(outcomes, *true_pars)\n",
    "\n",
    "t = range(len(outcomes))\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(t, outcomes, 'o', label='Outcomes')\n",
    "plt.plot(t, .1 + (responses * .8), 'o', label='Responses')\n",
    "plt.plot(t, action_probs, label='Belief [P(Outcome)]')\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(pars, outcomes, responses):\n",
    "    '''\n",
    "    This is the key function.\n",
    "    Arguments are a vector of parameters, a list of outcomes and a list of responses.\n",
    "    How likely is a RL agent governed by these parameters to produce these responses,\n",
    "    given these outcomes?\n",
    "    '''\n",
    "    learning_rate, slope = pars\n",
    "    action_probs = get_agent_response_probs(outcomes, learning_rate, slope)\n",
    "    lik = np.where(responses==1, action_probs, 1 - action_probs)\n",
    "    return np.sum(np.log(lik))\n",
    "\n",
    "log_likelihood(true_pars, outcomes, responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling over Grid\n",
    "\n",
    "This model is pretty simple (only two parameters),\n",
    "and the log-likelihood function is very fast to run.\n",
    "This makes it possible to evaluate the log-likelihood across a large grid of parameters,\n",
    "without the need for MCMC sampling.\n",
    "Let's do this for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "npoints = 101\n",
    "param_grid = pd.DataFrame(itertools.product(np.linspace(0, 1.5, npoints), # Possible learning rates\n",
    "                                            np.linspace(0, 2, npoints)),  # Possible slopes\n",
    "                         columns=['rate', 'slope'])\n",
    "\n",
    "def f(pars):\n",
    "    return log_likelihood(pars.values, outcomes, responses)\n",
    "\n",
    "## Get log-likelihood for each rate x slope combination.\n",
    "ll = [f(p) for i, p in param_grid.iterrows()]\n",
    "ll = np.array(ll)\n",
    "## Replace NaN and -inf with the smallest finite value.\n",
    "mask = (np.isnan(ll)) | (ll == -np.inf)\n",
    "ll[mask] = ll[~mask].min()\n",
    "param_grid['ll'] = ll\n",
    "## Transform log-likelihoods into normalised probabilties.\n",
    "prob_adj = np.exp(ll - np.max(ll))\n",
    "param_grid['prob_adj'] = prob_adj / prob_adj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = param_grid.pivot_table(index='rate', columns='slope', values='ll')\n",
    "X.columns = np.array(X.columns).round(2)\n",
    "X.index = np.array(X.index).round(2)\n",
    "sns.heatmap(X , cmap='jet', vmin=None)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Log-Likelihood (trucuated scale)')\n",
    "sns.heatmap(X , cmap='jet', vmin=-800)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Learning Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform the existing matrix\n",
    "sns.heatmap(np.exp(X - X.max().max()), cmap='jet')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Likelihood')\n",
    "\n",
    "## Or use the existing column\n",
    "# X = param_grid.pivot_table(index='rate', columns='slope', values='prob_adj')\n",
    "# X.columns = np.array(X.columns).round(2)\n",
    "# X.index = np.array(X.index).round(2)\n",
    "# sns.heatmap(X , cmap='jet', vmin=None)\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.xlabel('Slope')\n",
    "# plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sample values directly. from this grid (with some noise) to obtain posterior samples \n",
    "comparable to what we would obtain from MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample columns with probabilities proportional to their likelihoods.\n",
    "p = np.exp(ll  - np.max(ll))\n",
    "sample_indices = np.random.choice(param_grid.index, size=1000, replace=True, p=p/p.sum())\n",
    "grid_posterior = param_grid.iloc[sample_indices]\n",
    "def r(): # Add noise\n",
    "    return np.random.normal(0, .0001, 1000)\n",
    "\n",
    "def draw_x(x, y):\n",
    "    plt.text(x, y, 'x',\n",
    "             horizontalalignment='center', verticalalignment='center',\n",
    "             fontdict={'color':'red', 'size':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(grid_posterior['slope'] + r(), grid_posterior['rate'] + r(), shade=False)\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 1)\n",
    "draw_x(true_pars[1], true_pars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(grid_posterior['slope'] + r(), grid_posterior['rate'] + r(), alpha=.2)\n",
    "plt.xlabel('Slope')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 1)\n",
    "draw_x(true_pars[1], true_pars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_posterior[['rate', 'slope']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.abs(grid_posterior['slope'] - true_pars[1]) < .025\n",
    "grid_posterior.loc[m, 'rate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = [grid_posterior[v] for v in ['rate', 'slope']]\n",
    "plt.scatter(a-b, a+b)\n",
    "plt.xlabel('<- Learning noise | Decision noise ->')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.vlines(0, linestyle='dashed', *plt.ylim())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_func():\n",
    "    a = np.random.uniform(0, .5)\n",
    "    b = np.random.uniform(0, .5)\n",
    "    return [a, b]\n",
    "\n",
    "def f(pars):\n",
    "    log_prior = np.sum(stats.norm.logpdf(pars, 0, 2))\n",
    "    ll = log_likelihood(pars, outcomes, responses)\n",
    "    if np.isnan(ll):\n",
    "        return  log_prior - 1e+5\n",
    "    else:\n",
    "        return log_prior + ll\n",
    "sampler = ezmc.MetropolisSampler(func=f,\n",
    "                                 par_names=['learning_rate', 'slope'],\n",
    "                                 n_chains=4,\n",
    "                                 init_func=init_func, proposal_sd=.05,\n",
    "                                verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.sample_chains(n=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = sampler.get_chains()\n",
    "fig = ezmc.viz.traceplot(chains);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = sampler.get_results(burn_in=2000, thin=20)\n",
    "results = sampler.get_results(burn_in=1000, thin=4)\n",
    "fig = ezmc.viz.traceplot(results, sampler.par_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "posterior = sampler.to_arviz(burn_in=1000, thin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(posterior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_joint(posterior, kind='scatter', joint_kwargs=dict(alpha=.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_joint(posterior, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(posterior, kind='ridgeplot',\n",
    "               linewidth=1, combined=True, ridgeplot_overlap=1, colors='skyblue',\n",
    "               figsize=(9, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[sampler.par_names].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = results.mean()\n",
    "estimates_se = results.std()\n",
    "# trans_est_pars = [estimates[p] for p in sampler.par_names]\n",
    "# est_pars = untransform_pars(trans_est_pars)\n",
    "est_pars = [estimates[p] for p in sampler.par_names]\n",
    "est_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(results[sampler.par_names + ['ll']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_responses, sim_action_probs = get_agent_responses(outcomes, *est_pars)\n",
    "\n",
    "t = range(len(outcomes))\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(t, outcomes, 'o', label='Outcomes')\n",
    "plt.plot(t, .1 + (responses * .8), 'o', label='Responses')\n",
    "plt.plot(t, action_probs, label='True Belief')\n",
    "plt.plot(t, sim_action_probs, label='Estimated Belief')\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "for i, row in results.sample(100).iterrows():\n",
    "    p = row[sampler.par_names].values\n",
    "    _, sim_action_probs = get_agent_responses(outcomes, *p)\n",
    "    plt.plot(t, sim_action_probs, label='__none__', alpha=.1, color='b')\n",
    "plt.plot(t, sim_action_probs, label='Estimated Belief', alpha=.1, color='b') # Plot again to get legend\n",
    "plt.plot(t, action_probs, label='True Belief', color='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
